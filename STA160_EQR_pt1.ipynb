{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(zip_file):\n",
    "    temp_directory = tempfile.TemporaryDirectory()  # use a temporary directory for file unzipping\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(temp_directory.name)\n",
    "    return temp_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths for output csvs:\n",
    "data_csv_path = r\"[insert your filepath]\" \n",
    "\n",
    "# main zip filepath \n",
    "main_zip = r'[insert filepath of downloaded eqr file]'\n",
    "main_temp_directory = unzip(main_zip)\n",
    "\n",
    "# creating df for data needed\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_empty_values(df, seller_zip):\n",
    "    if df[['seller_company_name', 'product_name', 'point_of_delivery_balancing_authority', 'increment_name']].isnull().any().any():\n",
    "        print(f\"Null values in: {seller_zip}\")\n",
    "    elif df[['seller_company_name', 'product_name', 'point_of_delivery_balancing_authority', 'increment_name']].isna().any().any():\n",
    "        print(f\"NA values in: {seller_zip}\")\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count = 0\n",
    "for seller_zip in os.listdir(main_temp_directory.name):  # iterate through seller zip files\n",
    "    if seller_zip.endswith('.zip') or seller_zip.endswith('.ZIP'):\n",
    "        seller_zip_path = os.path.join(main_temp_directory.name, seller_zip)\n",
    "        # print(f\"Unzipping seller zip file: {seller_zip_path}\")\n",
    "\n",
    "        seller_temp_directory = unzip(seller_zip_path)  # unzip seller zip files to a secondary temp directory --> 4 mins\n",
    "        # print(f\"File names: {os.listdir(seller_temp_directory.name)}\")\n",
    "\n",
    "        for transaction_file in os.listdir(seller_temp_directory.name):  # iterate over unzipped transaction files\n",
    "            if transaction_file.endswith('transactions.csv') or transaction_file.endswith('transactions.CSV'):\n",
    "                transaction_filepath = os.path.join(seller_temp_directory.name, transaction_file)\n",
    "                # print(f\"Processing transaction file: {transaction_filepath}\")\n",
    "\n",
    "                file_count = file_count + 1\n",
    "                # print(f\"File Count: {file_count}\")\n",
    "                \n",
    "                try:\n",
    "                    transaction_df = pd.read_csv(transaction_filepath, encoding='cp1252', low_memory=False)  # read in csv and filter data\n",
    "                    # print(f\"Read {len(transaction_df)} rows from {transaction_filepath}\")\n",
    "                    # print(transaction_df.head())  \n",
    " \n",
    "                    invalid_zip = check_for_empty_values(transaction_df, seller_zip)\n",
    "                    if invalid_zip:\n",
    "                        print(f\"Invalid data in {invalid_zip}\")\n",
    "                        continue\n",
    "                    \n",
    "\n",
    "                    # add in if statement to see if rows are > 0 \n",
    "                    filtered_data = transaction_df[\n",
    "                        (transaction_df['product_name'] == 'CAPACITY') &\n",
    "                        (transaction_df['increment_name'].isin(['M', 'Y'])) &\n",
    "                        (transaction_df['point_of_delivery_balancing_authority'] == 'CISO')\n",
    "                    ]\n",
    "                    filtered_data.reset_index(drop = True)\n",
    "                    \n",
    "                    # print(f\"filtered data: {filtered_data.head()}\")\n",
    "\n",
    "                    # print(f\"Filtered down to {len(filtered_data)} rows\")\n",
    "                    # print(filtered_data.head())  \n",
    "\n",
    "                    # check if filtered data exists before doing if length statement --> fix syntax.\n",
    "                    if filtered_data is not None:\n",
    "                        if len(filtered_data) > 0:\n",
    "                            data = pd.concat([data, filtered_data], ignore_index=True)  # append filtered data to data\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {seller_zip}: {e}\")\n",
    " \n",
    "                \n",
    "columns_to_delete = ['ferc_tariff_reference', 'contract_service_agreement', 'transaction_unique_identifier', 'exchange_brokerage_service', 'product_name', 'total_transmission_charge']\n",
    "data.drop(columns=columns_to_delete, inplace=True, errors='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data)) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(data_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
